data <- read.csv("./Levels_Fyi_Salary_Data.csv")
data <- read.csv(".data/Levels_Fyi_Salary_Data.csv")
data <- read.csv("./data/Levels_Fyi_Salary_Data.csv")
## 75% of the sample size
smp_size <- floor(0.75 * nrow(final_df))
## set the seed to make your partition reproducible
set.seed(123)
train_ind <- sample(seq_len(nrow(final_df)), size = smp_size)
train <- final_df[train_ind, ]
## 75% of the sample size
smp_size <- floor(0.75 * nrow(final_df))
## set the seed to make your partition reproducible
set.seed(123)
train_ind <- sample(seq_len(nrow(data)), size = smp_size)
## 75% of the sample size
smp_size <- floor(0.75 * nrow(data))
## set the seed to make your partition reproducible
set.seed(123)
train_ind <- sample(seq_len(nrow(data)), size = smp_size)
train <- final_df[train_ind, ]
test <- final_df[-train_ind, ]
test <- subset(test,select=-c(basesalary))
train <- data[train_ind, ]
test <- data[-train_ind, ]
test <- subset(test,select=-c(basesalary))
data <- read.csv("./data/Levels_Fyi_Salary_Data.csv")
## 75% of the sample size
smp_size <- floor(0.8 * nrow(data))
## set the seed to make your partition reproducible
set.seed(123)
train_ind <- sample(seq_len(nrow(data)), size = smp_size)
train <- data[train_ind, ]
test <- data[-train_ind, ]
test <- subset(test,select=-c(basesalary))
## 75% of the sample size
smp_size <- floor(0.9 * nrow(data))
## set the seed to make your partition reproducible
set.seed(123)
train_ind <- sample(seq_len(nrow(data)), size = smp_size)
train <- data[train_ind, ]
test <- data[-train_ind, ]
View(data)
View(data)
View(test)
View(data)
source("~/leon/finalproject-finalproject_group7/code/rlm/Final_rlm.R", echo=TRUE)
source("~/leon/finalproject-finalproject_group7/code/rlm/Final_rlm.R", echo=TRUE)
source("~/leon/finalproject-finalproject_group7/code/rlm/Final_rlm.R", echo=TRUE)
#read data
train <- read.csv("./data/train_salary.csv", encoding = "UTF-8")
test <- read.csv("./data/test_salary.csv", encoding = "UTF-8")
head(train)
colnames(train)[1]
colnames(train)[-1]
colnames(train)[12]
colnames(train)[13]
source("~/leon/finalproject-finalproject_group7/code/rlm/Final_rlm.R", echo=TRUE)
library(Metrics)
library(caret)
library(e1071)
library(mlbench)
library(Metrics)
min_max_norm <- function(x) {
(x - min(x)) / (max(x) - min(x))
}
#read data
train <- read.csv("./data/train_salary.csv", encoding = "UTF-8")
test <- read.csv("./data/test_salary.csv", encoding = "UTF-8")
#select feature
#train <- train[, -c(1, 3, 4, 5, 6, 7, 8, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26)]
#test <- test[, -c(1, 3, 4, 5, 6, 7, 8, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26)]
select_feat =  c("company" ,"title","tag" ,"basesalary" , "gender" ,"Race","Education" )
drop_feat = setdiff(colnames(train),select_feat)
#test target:base salary
# train <- subset(train, select = select_feat)
# test <- test$basesalary
train <- train[, -c(1, 3, 5, 11,13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24)]
test <- test[, -c(1, 3, 5, 11,13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24)]
#drop na
train <- na.omit(train)
test <- na.omit(test)
print(any(is.na(train)))
print(any(is.na(test)))
#One hot
#dummy <- dummyVars(" ~ .", data=train)
#train <- data.frame(predict(dummy, newdata = train))
#dmy <- dummyVars(" ~ .", data = test)
#test <- data.frame(predict(dmy, newdata = test))
#Label Encoding
# for (i in c(1,2,5,7,10,11)){
for (i in c("company" ,"title","tag", "gender" ,"Race","Education" )){
# print(train[, i])
train[, i] <- as.numeric(factor(train[, i]))
test[, i] <- as.numeric(factor(test[, i]))
}
#test target:base salary
test_X <- subset(test, select = -c(basesalary))
test_Y <- test$basesalary
#model
train_ctrl <- trainControl(method = "cv", number = 5)
tune_grid <- expand.grid(nrounds = 200,
max_depth = 10,
eta = 0.03,
gamma = 0.01,
colsample_bytree = 0.75,
min_child_weight = 0,
subsample = 0.5)
# xgboost train
# fit_rlm_cv <- train(basesalary ~ ., data = train, objective="reg:squarederror", method = 'xgbTree',
# trControl = train_ctrl, tuneGrid = tune_grid, tuneLength = 10)
# rf train
#fit_rlm_cv <- train(basesalary ~ . , data = train,method = 'ranger',tuneLength = 10,
trControl = train_ctrl,num.trees = 700,importance = "permutation")
# lm svm train
fit_rlm_cv <- train(basesalary ~ ., data = train,  method = 'lm',  trControl = train_ctrl)
#base salary
names(test_Y) <- "basesalary"
#predict base salary
pred_test <- data.frame(predict(fit_rlm_cv, test_X))
names(pred_test) <- "Pred_basesalary"
#E
test_E <- data.frame((test_Y - pred_test))
names(test_E) <- "E"
#output file
test_output <- data.frame(
basesalary = test_Y,
Pred_basesalary = pred_test,
E = test_E,
stringsAsFactors = F
)
write.csv(test_output, file = "Output_use_Test_data.csv", row.names = FALSE)
#feature Importance
importance <- varImp(fit_rlm_cv, scale = FALSE)
print(importance)
plot(importance)
#RMSE
RMSE <- sqrt(sum((test_Y - pred_test)^2) / nrow(pred_test))
print(paste0("RMSE:", round(RMSE, 2)))
library(caret)
library(e1071)
library(mlbench)
library(Metrics)
min_max_norm <- function(x) {
(x - min(x)) / (max(x) - min(x))
}
#read data
train <- read.csv("./data/train_salary.csv", encoding = "UTF-8")
test <- read.csv("./data/test_salary.csv", encoding = "UTF-8")
#select feature
#train <- train[, -c(1, 3, 4, 5, 6, 7, 8, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26)]
#test <- test[, -c(1, 3, 4, 5, 6, 7, 8, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26)]
select_feat =  c("company" ,"title","tag" ,"basesalary" , "gender" ,"Race","Education" )
drop_feat = setdiff(colnames(train),select_feat)
#test target:base salary
# train <- subset(train, select = select_feat)
# test <- test$basesalary
train <- train[, -c(1, 3, 5, 11,13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24)]
test <- test[, -c(1, 3, 5, 11,13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24)]
#drop na
train <- na.omit(train)
test <- na.omit(test)
print(any(is.na(train)))
print(any(is.na(test)))
#One hot
#dummy <- dummyVars(" ~ .", data=train)
#train <- data.frame(predict(dummy, newdata = train))
#dmy <- dummyVars(" ~ .", data = test)
#test <- data.frame(predict(dmy, newdata = test))
#Label Encoding
# for (i in c(1,2,5,7,10,11)){
for (i in c("company" ,"title","tag", "gender" ,"Race","Education" )){
# print(train[, i])
train[, i] <- as.numeric(factor(train[, i]))
test[, i] <- as.numeric(factor(test[, i]))
}
#test target:base salary
test_X <- subset(test, select = -c(basesalary))
test_Y <- test$basesalary
#model
train_ctrl <- trainControl(method = "cv", number = 5)
tune_grid <- expand.grid(nrounds = 200,
max_depth = 10,
eta = 0.03,
gamma = 0.01,
colsample_bytree = 0.75,
min_child_weight = 0,
subsample = 0.5)
# xgboost train
# fit_rlm_cv <- train(basesalary ~ ., data = train, objective="reg:squarederror", method = 'xgbTree',
# trControl = train_ctrl, tuneGrid = tune_grid, tuneLength = 10)
# rf train
#fit_rlm_cv <- train(basesalary ~ . , data = train,method = 'ranger',tuneLength = 10,
#                    trControl = train_ctrl,num.trees = 700,importance = "permutation")
# lm svm train
fit_rlm_cv <- train(basesalary ~ ., data = train,  method = 'lm',  trControl = train_ctrl)
#base salary
names(test_Y) <- "basesalary"
#predict base salary
pred_test <- data.frame(predict(fit_rlm_cv, test_X))
names(pred_test) <- "Pred_basesalary"
#E
test_E <- data.frame((test_Y - pred_test))
names(test_E) <- "E"
#output file
test_output <- data.frame(
basesalary = test_Y,
Pred_basesalary = pred_test,
E = test_E,
stringsAsFactors = F
)
write.csv(test_output, file = "Output_use_Test_data.csv", row.names = FALSE)
#feature Importance
importance <- varImp(fit_rlm_cv, scale = FALSE)
print(importance)
plot(importance)
#RMSE
RMSE <- sqrt(sum((test_Y - pred_test)^2) / nrow(pred_test))
print(paste0("RMSE:", round(RMSE, 2)))
test_Y
length(test_Y)
length(pred_test)
\pred_test
pred_test
4007+1165
length(pred_test)
length(pred_test)
length(test_Y)
# lm svm train
fit_rlm_cv <- train(basesalary ~ ., data = train,  method = 'lm',  trControl = train_ctrl)
#base salary
names(test_Y) <- "basesalary"
#predict base salary
pred_test <- data.frame(predict(fit_rlm_cv, test_X))
pred_test
length(pred_test)
type(pred_test)
class(pred_test)
nrow(pred_test)
names(pred_test) <- "Pred_basesalary"
nrow(pred_test)
class(pred_test)
pred_test
?/names
?names
source("~/leon/finalproject-finalproject_group7/code/rlm/Final_rlm.R", echo=TRUE)
source("~/leon/finalproject-finalproject_group7/code/rlm/Final_rlm.R", echo=TRUE)
source("~/leon/finalproject-finalproject_group7/code/rlm/Final_rlm.R", echo=TRUE)
source("~/leon/finalproject-finalproject_group7/code/rlm/Final_rlm.R", echo=TRUE)
length(test_Y)
length(pred_test)
View(pred_test)
length(test_output$Pred_basesalary)
length(test_output$basesalary)
print(rmse(test_output$basesalary,test_output$Pred_basesalary))
print(paste0("RMSE:", round(RMSE, 2)))
source("~/leon/finalproject-finalproject_group7/code/rlm/Final_rlm.R", echo=TRUE)
source("~/leon/finalproject-finalproject_group7/code/rlm/Final_rlm.R", echo=TRUE)
source("~/leon/finalproject-finalproject_group7/code/rlm/Final_rlm.R", echo=TRUE)
source("~/leon/finalproject-finalproject_group7/code/rlm/Final_rlm.R", echo=TRUE)
View(test_output)
View(test_output)
View(test_output)
source("~/leon/finalproject-finalproject_group7/code/rlm/Final_rlm.R", echo=TRUE)
print(paste0("R2_Score:", round(R2_Score(test_output$basesalary,test_output$Pred_basesalary), 2)))
(MLmetrics)
installed.packages("MLmetrics")
library(MLmetrics)
print(paste0("R2_Score:", round(r2_Score(test_output$basesalary,test_output$Pred_basesalary), 2)))
#read data
train <- read.csv("./data/train_salary.csv", encoding = "UTF-8")
tarin[27,]
train[27,]
